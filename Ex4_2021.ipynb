{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Ex4_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonaden94/deepl-ecker-21-22/blob/main/Ex4_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms0joNfRzag-"
      },
      "source": [
        "# Exercise Sheet 4 - Transfer Learning for Saliency Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzBpDwtBzd46"
      },
      "source": [
        " * Deep Learning\n",
        " * Instructor: Alexander Ecker\n",
        " * Tutors: Max Burg, Laura Pede\n",
        " * Due date: **Tue, Dec 21, noon**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqZXvojiz0D6"
      },
      "source": [
        "In this assignment you will learn how to use transfer learning to predict where people will look in images. We will work with the MIT 1003 dataset which consists of 1003 images together with fixation data from human subjects. Transfer learning allows us to reuse the features from a model that has been pretrained on a larger dataset. Here we will use VGG19 pretrained on ImageNet.\n",
        "\n",
        "The goals of this assignment are as follows:\n",
        "\n",
        "*   Extract features from a model pretrained on ImageNet.\n",
        "*   Implement a simple readout network and train it on the data.\n",
        "*   Define a loss function and a seperate evaluation metric.\n",
        "*   Visualize the best and the worst results.\n",
        "\n",
        "## Hints\n",
        "\n",
        "To understand the idea of the exercise sheet, inspired by a paper called DeepGaze I, do the following.\n",
        "\n",
        "* Review the lecture\n",
        "* Tt will be very helpful to read the according paper [KÃ¼mmerer, Theis, and Bethge (2015)](https://arxiv.org/abs/1411.1045). \n",
        "\n",
        "Although the general idea of the exercise will be the same, we changed some details: for example, we will use VGG instead of caffe net, will not do the same thoroughly analysis and changed some other details as well to make this exercise simpler.\n",
        "\n",
        "*Do not hesitate to ask questions and ideally discuss them with your fellow students and tutors on Rocket Chat! We will monitor the channel to provide you help if your discussions get stuck. Also, we are happy to help in our office hours - looking forward seeing you there!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ4jpxuU2CqD"
      },
      "source": [
        "### IMPORTANT SUBMISSION INSTRUCTIONS\n",
        "\n",
        "- When you're done, download the notebook and rename it to \\<surname1\\>_\\<surname2\\>_\\<surname3\\>.ipynb\n",
        "- Only submit the ipynb file, no other file is required\n",
        "- Submit only once\n",
        "- The deadline is strict\n",
        "- You are required to present your solution in the tutorial; submission of the notebook alone is not sufficient\n",
        "\n",
        "Implementation\n",
        "- Only change code to replace placeholders. Leave the other code as is. In addition to the python packages loaded below you are allowed to use any packages you want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aEctsMZ2a6Z"
      },
      "source": [
        "**Importing required libraries.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57JMWl2ZDwaq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from skimage import io, transform\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from google.colab import drive\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKuT7TZ7D2nM"
      },
      "source": [
        "**Get the data**\n",
        "\n",
        "The MIT 1003 dataset is publicly available at https://people.csail.mit.edu/tjudd/WherePeopleLook/index.html\n",
        "\n",
        "For your convenience there is a shared folder on Google Drive: https://drive.google.com/drive/folders/1GoYw3jp9kWLmHN7qylDS5QTo_ebnaMDD?usp=sharing\n",
        "You can click the link and add the folder to your Drive (it does not count into your disk quota).\n",
        "\n",
        "If you're using Colab, you can uncomment the code in the following cell to mount your Google drive. Otherwise, you need to download the data and enter the path to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHd5UFWkEc87"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW_BuLYjD2na"
      },
      "source": [
        "main_path = \"/content/drive/My Drive/Work/Teaching/Deep Learning\"\n",
        "data_path = os.path.join(main_path, \"MIT_1003\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hstop-eGD2nm"
      },
      "source": [
        "**Prepare the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHwpWifaDwbJ"
      },
      "source": [
        "images_files_all = [\n",
        "    os.path.join(data_path, \"ALLSTIMULI\", f)\n",
        "    for f in os.scandir(os.path.join(data_path, \"ALLSTIMULI\"))\n",
        "    if f.path.endswith(\".jpeg\")\n",
        "]\n",
        "print(\"Total Number of Images: {} (should be 1003)\".format(len(images_files_all)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw_kppidDwbY"
      },
      "source": [
        "# fix the seed for reproducible splitting\n",
        "np.random.seed(1234)\n",
        "train_idx = np.random.choice(len(images_files_all), len(images_files_all) // 2, replace=False)\n",
        "test_idx = np.setdiff1d(np.arange(len(images_files_all)), train_idx)\n",
        "\n",
        "images_files = {}\n",
        "images_files[\"train\"] = [images_files_all[i] for i in train_idx]\n",
        "images_files[\"test\"] = [images_files_all[i] for i in test_idx]\n",
        "print(\"Number of Train Images: {}\".format(len(images_files[\"train\"])))\n",
        "print(\"Number of Test Images: {}\".format(len(images_files[\"test\"])))\n",
        "\n",
        "fixation_maps_binary_files = {}\n",
        "fixation_maps_binary_files[\"train\"] = [\n",
        "    os.path.join(data_path, \"ALLFIXATIONMAPS\", os.path.splitext(os.path.basename(filename))[0] + \"_fixPts.jpg\")\n",
        "    for filename in images_files[\"train\"]\n",
        "]\n",
        "fixation_maps_binary_files[\"test\"] = [\n",
        "    os.path.join(data_path, \"ALLFIXATIONMAPS\", os.path.splitext(os.path.basename(filename))[0] + \"_fixPts.jpg\")\n",
        "    for filename in images_files[\"test\"]\n",
        "]\n",
        "fixation_maps_blurred_files = {}\n",
        "fixation_maps_blurred_files[\"train\"] = [\n",
        "    os.path.join(data_path, \"ALLFIXATIONMAPS\", os.path.splitext(os.path.basename(filename))[0] + \"_fixMap.jpg\")\n",
        "    for filename in images_files[\"train\"]\n",
        "]\n",
        "fixation_maps_blurred_files[\"test\"] = [\n",
        "    os.path.join(data_path, \"ALLFIXATIONMAPS\", os.path.splitext(os.path.basename(filename))[0] + \"_fixMap.jpg\")\n",
        "    for filename in images_files[\"test\"]\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_ws-tlaDwcI"
      },
      "source": [
        "**Show an example from the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4eAt0FDwcL"
      },
      "source": [
        "image = io.imread(images_files[\"train\"][0])\n",
        "binary_map = io.imread(fixation_maps_binary_files[\"train\"][0])\n",
        "blurred_map = io.imread(fixation_maps_blurred_files[\"train\"][0])\n",
        "fixations = np.where(binary_map)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nr-EMrZDwcg"
      },
      "source": [
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
        "ax1.axis(\"off\")\n",
        "ax1.imshow(image)\n",
        "ax2.axis(\"off\")\n",
        "ax2.imshow(blurred_map, cmap=\"viridis_r\")\n",
        "ax3.axis(\"off\")\n",
        "ax3.imshow(image, alpha=0.5)\n",
        "ax3.scatter(fixations[1], fixations[0], s=1, marker=\".\", c=\"b\")\n",
        "ax4.axis(\"off\")\n",
        "ax4.imshow(image)\n",
        "ax4.imshow(blurred_map, alpha=0.5, cmap=\"viridis_r\")\n",
        "fig.tight_layout()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgUxMoe_Dwcv"
      },
      "source": [
        "**Preprocess images and maps**\n",
        "\n",
        "The images have different sizes and orientations. To simplify our task we downscale the images and crop them to a size of 256x256 pixels. At this size, all of the images should fit into memory at once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkasX89_Dwcy"
      },
      "source": [
        "def preprocess_data(images_paths, fixations_binary_paths, fixations_blurred_paths, shape):\n",
        "    transform = torchvision.transforms.Compose(\n",
        "        [\n",
        "            torchvision.transforms.ToPILImage(),\n",
        "            torchvision.transforms.Resize(shape),\n",
        "            torchvision.transforms.CenterCrop(shape),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    n = len(images_paths)\n",
        "    ims = np.empty((n, shape, shape, 3), dtype=np.int)\n",
        "    fixs_binary = np.empty((n, shape, shape))\n",
        "    fixs_blurred = np.empty((n, shape, shape))\n",
        "\n",
        "    for i, path in enumerate(tqdm(images_paths)):\n",
        "        image = io.imread(path)\n",
        "        image = transform(image)\n",
        "        image = np.array(image, dtype=np.int)\n",
        "        ims[i] = image\n",
        "\n",
        "    for i, path in enumerate(tqdm(fixations_binary_paths)):\n",
        "        fixations_binary = io.imread(path, 0)\n",
        "        fixations_binary = transform(fixations_binary)\n",
        "        fixations_binary = np.array(fixations_binary)\n",
        "        fixs_binary[i] = fixations_binary\n",
        "\n",
        "    for i, path in enumerate(tqdm(fixations_blurred_paths)):\n",
        "        fixations_blurred = io.imread(path, 0)\n",
        "        fixations_blurred = transform(fixations_blurred)\n",
        "        fixations_blurred = np.array(fixations_blurred)\n",
        "        fixs_blurred[i] = fixations_blurred\n",
        "\n",
        "    data = {\"images\": ims, \"fixations_binary\": fixs_binary, \"fixations_blurred\": fixs_blurred}\n",
        "    return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH-V757fkvTJ"
      },
      "source": [
        "# If data is already preprocessed and saved, load it, otherwise preprocess and save it.\n",
        "# If you do not whish to save the data comment the according lines.\n",
        "# If you want to re-run data preprocessing, you may have to delete the saved file.\n",
        "\n",
        "train_data_file = os.path.join(main_path, \"train_data.npy\")\n",
        "\n",
        "if os.path.isfile(train_data_file):\n",
        "    train_data = np.load(train_data_file, allow_pickle=True)[()]\n",
        "else:\n",
        "    train_data = preprocess_data(\n",
        "        images_files[\"train\"], fixation_maps_binary_files[\"train\"], fixation_maps_blurred_files[\"train\"], 256\n",
        "    )\n",
        "    np.save(train_data_file, train_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG7BDv0hDwdH"
      },
      "source": [
        "**Implement a PyTorch dataset for our data**\n",
        "\n",
        "We need the `torch.utils.data.Dataset`  to access the data conveniently. Later, it is required to have access to the data through this class to build a Pytorch dataloader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0xgIE_sDwdJ"
      },
      "source": [
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, preprocessed_data, features=None):\n",
        "        self.features = features\n",
        "        self.data = preprocessed_data\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        raw_image = self.data[\"images\"][key]\n",
        "\n",
        "        normalized_image = raw_image.astype(np.float32) / 255.0  # -> [0, 1]\n",
        "        normalized_image -= np.array([0.485, 0.456, 0.406])  # subtract mean\n",
        "        normalized_image /= np.array([0.229, 0.224, 0.225])  # divide by SD\n",
        "        normalized_image = normalized_image.transpose(2, 0, 1)  # HWC -> CHW\n",
        "\n",
        "        fixations_binary = self.data[\"fixations_binary\"][key]\n",
        "        fixations_blurred = self.data[\"fixations_blurred\"][key]\n",
        "\n",
        "        data = {\n",
        "            \"raw_image\": raw_image,\n",
        "            \"normalized_image\": normalized_image,\n",
        "            \"fixations_binary\": fixations_binary,\n",
        "            \"fixations_blurred\": fixations_blurred,\n",
        "        }\n",
        "\n",
        "        if self.features is not None:\n",
        "            data[\"features\"] = self.features[key]\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[\"images\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS8hk7GfD2ot"
      },
      "source": [
        "The collate_fn will be used in the dataloader. It converts the batched data into tensors. We use a sparse tensor for the binary fixations because they contain mostly zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KBNBWMXD2ov"
      },
      "source": [
        "def to_sparse(x):\n",
        "    \"\"\"converts dense tensor x to sparse format\"\"\"\n",
        "    x_typename = torch.typename(x).split(\".\")[-1]\n",
        "    sparse_tensortype = getattr(torch.sparse, x_typename)\n",
        "\n",
        "    indices = torch.nonzero(x)\n",
        "    if len(indices.shape) == 0:  # if all elements are zeros\n",
        "        return sparse_tensortype(*x.shape)\n",
        "    indices = indices.t()\n",
        "    values = x[tuple(indices[i] for i in range(indices.shape[0]))]\n",
        "    return sparse_tensortype(indices, values, x.size())\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_data = {\n",
        "        \"image\": torch.tensor([item[\"normalized_image\"] for item in batch]),\n",
        "        \"fixations_binary\": to_sparse(torch.tensor([item[\"fixations_binary\"] for item in batch])),\n",
        "        \"fixations_blurred\": torch.tensor([item[\"fixations_blurred\"] for item in batch]),\n",
        "    }\n",
        "    if \"features\" in batch[0].keys():\n",
        "        batch_data[\"features\"] = torch.tensor([item[\"features\"] for item in batch], dtype=torch.float)\n",
        "    return batch_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-roY4tNDweN"
      },
      "source": [
        "**Compute center bias**\n",
        "\n",
        "People tend to look towards the center of the image. This is both due to a bias in our expectations as well as the tendency of photographers to place the interesting objects in the center of the photo. Thus, in the fixation data there is a bias towards the center of the image. We incorporate this bias into our model explicitly. \n",
        "\n",
        "**TO DO:** To compute the center bias, \n",
        "1. sum all the binary fixation maps, \n",
        "1. normalize by dividing through the maximum value\n",
        "1. apply a Gaussian filter with standard deviation 10 to smooth the result\n",
        "1. and compute the natural logarithm\n",
        "\n",
        "*Hints:*\n",
        "- Use the `ImageDataset` class to directly access the data; no pytorch data loader is required here.\n",
        "- For Gaussian filtering, you can use `gaussian_filter` from `scipy.ndimage`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3-itd9hDweP"
      },
      "source": [
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "# Instantiate the pytorch dataset. (Note that although it contains the same data,\n",
        "# as `train_data` above, the objects are different. Here, we could use `train_data`)\n",
        "# instead of `dataset_train`, however, to build a pytorch dataloader later, we\n",
        "# have to use the `dataset_train` object.\n",
        "\n",
        "dataset_train = ImageDataset(train_data)\n",
        "fixations_binary = dataset_train.data[\"fixations_binary\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XBPMSZkiO3o"
      },
      "source": [
        "# TODO\n",
        "center_bias = ...  # (should be 1 x 256 x 256)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhM7Cp_eD2pD"
      },
      "source": [
        "Plot the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH9fDjZ0Dwel"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(center_bias[0], cmap=\"viridis_r\")\n",
        "cb = plt.colorbar().set_label(\"log density\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Center bias\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQcCDchXiO3q"
      },
      "source": [
        "Your plot should look like this:\n",
        "\n",
        "![download.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A67ttHkDwey"
      },
      "source": [
        "Save/Load center bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjrrv34aDwez"
      },
      "source": [
        "center_bias_file = os.path.join(main_path, \"center_bias.npy\")\n",
        "\n",
        "if os.path.isfile(center_bias_file):\n",
        "    center_bias = np.load(center_bias_file)\n",
        "else:\n",
        "    np.save(center_bias_file, center_bias)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjX1ydxkDwdl"
      },
      "source": [
        "**Extract feature maps**\n",
        "\n",
        "Load the VGG19 model pretrained on ImageNet. Use it to process the images in the train dataset: For each image, extract its feature map representation from the Conv2d layer `vgg19.features[30]`. You should save them in a Numpy array of shape `(num_feature_map_representations, num_channels, x, y)`.\n",
        "\n",
        "**Theory question and hint**:\n",
        "- Which shape do you expect for the numpy array? Calculate the values by hand\n",
        "- You can verify that you calculated correctly with the code you will write for this task\n",
        "\n",
        "*Hints:*\n",
        "- Here you will have to define and use a pytorch `DataLoader` object\n",
        "    - feed in the train set of type `torch.utils.data.Dataset` created above\n",
        "    - use the `collate_fn` defined above\n",
        "    - do not shuffle the images (i.e. the data points), so we can save the feature map representations of the images. That way, we can use the feature map representations later and still identify the according image we used to create them.\n",
        "- cf. https://pytorch.org/docs/stable/torchvision/models.html. If you are wondering if we normalized images, check code in `ImageDataset`\n",
        "- Define a `feature_extractor` object, containing those parts of the pre-trained VGG19 models that you need to textract the feature map representations from the Conv2d layer `vgg19.features[30]`\n",
        "    - Don't forget to put your feature extractor in evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U3rsUP6k8s9"
      },
      "source": [
        "#TODO\n",
        "vgg = \n",
        "feature_extractor =\n",
        "data_loader = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxRaNI9aiO3x"
      },
      "source": [
        "def compute_train_features( # TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdnFKp25Dwd0"
      },
      "source": [
        "**Save the features to a file**\n",
        "\n",
        "Processing the images can take a few minutes. However, you only have to do it once. Thus it is a good idea to save the features to a file that you can load again later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT7B2fZcDwd3"
      },
      "source": [
        "features_file = os.path.join(main_path, \"features_train.npy\")\n",
        "\n",
        "if os.path.isfile(features_file):\n",
        "    features = np.load(features_file)\n",
        "\n",
        "else:\n",
        "    features = compute_train_features()\n",
        "\n",
        "    # check if feature maps are computed correctly\n",
        "    # fmt: off\n",
        "    expected_values = np.array(\n",
        "    [[ -7.99193907 ,  -9.97434425 ,  -6.30443621 ,  -5.38638353 ,  -4.27384281,\n",
        "    -4.0693121  ,  -5.75616169 ,  -6.48476934 ,  -5.98380566 ,  -6.52242613],\n",
        "    [-12.36434174 , -16.65618324 , -11.27461529 ,  -8.19952297 ,  -3.27289772,\n",
        "    -1.19771433 ,  -3.19741416 ,  -6.47992802 ,  -6.5870204  ,  -7.18390512],\n",
        "    [-11.13755226 , -15.65487099 , -12.64397049 ,  -7.71314335 ,  -2.45429325,\n",
        "        0.83334196 ,  -0.64034951 ,  -5.03683281 ,  -4.65806484 ,  -4.50047112],\n",
        "    [-10.5068655  , -14.42764664 , -10.61693573 ,  -5.19931602 ,  -1.12161112,\n",
        "        0.89836073 ,  -0.5252769  ,  -3.71349239 ,  -2.97045493 ,  -2.79023504],\n",
        "    [ -7.34475327 , -10.47937965 ,  -7.02888393 ,  -3.53863454 ,  -0.80185205,\n",
        "    -0.74341547 ,  -1.12742841 ,  -2.42642498 ,  -2.1918633  ,  -2.38320088],\n",
        "    [ -6.56508207 , -10.2462101  ,  -7.95301008 ,  -5.73207569 ,  -2.83811665,\n",
        "    -3.51840949 ,  -3.68543339 ,  -3.03833508 ,  -3.84370446 ,  -3.34144878],\n",
        "    [ -7.19058847 , -11.19171238 , -10.3939085  ,  -9.02087402 ,  -7.91058254,\n",
        "    -8.43811989 ,  -7.81550455 ,  -6.3780117  ,  -7.06438923 ,  -4.87577438],\n",
        "    [ -6.39207697 ,  -9.84247875 , -10.04116726 ,  -9.37077713 ,  -9.32631779,\n",
        "    -8.01702595 ,  -8.88777161 ,  -7.13604116 ,  -6.65273285 ,  -4.70653677],\n",
        "    [ -5.39928961 ,  -8.16330624 ,  -9.64505863 , -10.31910038 , -11.08797836,\n",
        "    -9.06617165 ,  -8.1905756  ,  -7.1117115  ,  -5.28658915 ,  -3.31289601],\n",
        "    [ -6.93690252 ,  -8.61090851 ,  -8.46377468 ,  -8.70087719 , -10.07951546,\n",
        "    -9.06166553 ,  -7.16104031 ,  -6.44536161 ,  -4.36636829 ,  -1.53092551]]\n",
        "    )\n",
        "    # fmt: on\n",
        "    assert np.allclose(features[0, 0, :10, :10], expected_values), \"Feature maps look different than expected\"\n",
        "\n",
        "    np.save(features_file, features)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTsDojrc8QMi"
      },
      "source": [
        "Add the features to the dataset and define a data loader for training our model. Feel free to change the batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxaZPaakDwd_"
      },
      "source": [
        "dataset_train = ImageDataset(train_data, features=features)\n",
        "\n",
        "data_loader_train = torch.utils.data.DataLoader(\n",
        "    dataset_train,\n",
        "    shuffle=True,\n",
        "    batch_size=64,\n",
        "    collate_fn=collate_fn,\n",
        "    pin_memory=False,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iswz9l74DwdQ"
      },
      "source": [
        "**Define the model**\n",
        "\n",
        "Now we need to define the model we want to train. Two parts are necessary:\n",
        "\n",
        "1. Readout Network\n",
        "\n",
        "The readout network gets the feature maps we extracted from VGG19 as input. The network could be of arbitrary complexity but in our case we want to keep it simple: it contains only one layer that takes a linear combination of the features at each location (using 1x1 convolution).\n",
        "\n",
        "2. Finalizer\n",
        "\n",
        "The finalizer takes the output of the readout network and scales it up to the size of our images (256x256). It then applies a Gaussian filter to blur the result of the upscaling and adds the center bias. Finally, it performs normalization using a (log) softmax to return the logarithm of the fixation probability densities, later refered to as `log_density`.\n",
        "\n",
        "*Hints:*\n",
        "- What are in- and out-shapes of the readout network? What are the parameters you have to pass to the constructor of the 1x1 convolution, then?\n",
        "- Don't forget to give a learnable weight to the center bias, $\\alpha$ in [KÃ¼mmerer, Theis, and Bethge (2015)](https://arxiv.org/abs/1411.1045). \n",
        "- In `Finalizer` below, initialize `self.gaussian_blur = GaussianBlur2d()` and use `self.gaussian_blur` in `forward(...)`.\n",
        "- You might want to use `F.interpolate`\n",
        "- The finalizer output is of shape `(batch, x_pixels, y_pixels)`\n",
        "- Log softmax: As the finalizer should return the logarithm of the fixation probabilities, here is a hint rewriting the math of the paper cited above accordingly:\n",
        "$$\\ln p(x, y)=\\ln \\frac{\\exp (o(x, y))}{\\sum_{x, y} \\exp (o(x, y))} = \\ ?$$\n",
        "(Note that in the paper $\\log$ refers to the natural logarithm $\\ln$. Ignore the regularization term in this step). Hence, we recommend you to use `logsumexp` to compute the softmax in log-space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mJyxnt-ZZEz"
      },
      "source": [
        "class GaussianBlur2d(nn.Module):\n",
        "    \"\"\"\n",
        "    This class applies a Gaussian filter to a tensor. You should\n",
        "    use it *after* upscaling to image size (256x256). The kernel\n",
        "    size and the standard deviation are fixed and you don't need\n",
        "    to change them.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.kernel_size = 121\n",
        "        self.sigma = 20\n",
        "        self.pad = 60\n",
        "\n",
        "        grid = torch.arange(float(self.kernel_size)) - self.pad\n",
        "\n",
        "        kernel_shape_x = [1] * 4\n",
        "        kernel_shape_x[3] = self.kernel_size\n",
        "        grid_x = nn.Parameter(grid.view(kernel_shape_x), requires_grad=False)\n",
        "        self.kernel_x = torch.exp(-0.5 * (grid_x / self.sigma) ** 2)\n",
        "        self.kernel_x = self.kernel_x / self.kernel_x.sum()\n",
        "\n",
        "        kernel_shape_y = [1] * 4\n",
        "        kernel_shape_y[2] = self.kernel_size\n",
        "        grid_y = grid.view(kernel_shape_y)\n",
        "        self.kernel_y = torch.exp(-0.5 * (grid_y / self.sigma) ** 2)\n",
        "        self.kernel_y = self.kernel_y / self.kernel_y.sum()\n",
        "\n",
        "    def forward(self, tensor):\n",
        "        \"\"\"Applies the gaussian filter to the given tensor\"\"\"\n",
        "        out = F.conv1d(tensor, self.kernel_x, padding=self.pad)\n",
        "        out = F.conv1d(out, self.kernel_y)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXmiU0OtiO3y"
      },
      "source": [
        "#TODO\n",
        "readout_network = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSQ9C8kjk8s_"
      },
      "source": [
        "class Finalizer(nn.Module):\n",
        "    \"\"\"Returns logarithm of the fixation probability densities, shape: (batch, x_size, y_size)\"\"\"\n",
        "\n",
        "\n",
        "# TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vyoYLsYDwdY"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, readout_network, finalizer):\n",
        "        super().__init__()\n",
        "        self.readout_network = readout_network\n",
        "        self.finalizer = finalizer\n",
        "\n",
        "    def forward(self, x, centerbias):\n",
        "        x = self.readout_network(x)\n",
        "        x = self.finalizer(x, centerbias)\n",
        "        return x\n",
        "\n",
        "    def train(self, mode=True):\n",
        "        self.readout_network.train(mode=mode)\n",
        "        self.finalizer.train(mode=mode)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI6b6ou6DwfZ"
      },
      "source": [
        "finalizer = Finalizer()\n",
        "model = Model(readout_network, finalizer)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ZPvRojDweF"
      },
      "source": [
        "**Define the metrics**\n",
        "\n",
        "We use two different metrics, one for training and one for evaluating the performance of our model. Remember that we did this for the past exercises, too: back then, we used the cross-entropy loss for training and accuracy for validation.\n",
        "\n",
        "Here, for the training, we use the negative log-likelihood (NLL). Implement a function that calculates the negative log-likelihood of a fixation mask (which are the labels in our data) under the model prediction `log_density` (i.e. the logarithm of the fixation probability density maps). \n",
        "\n",
        "*Hints:* \n",
        "The negative log-likelihood we want to use is a slight modification of the equation (last one on page 3) given in KÃ¼mmerer, Theis, and Bethge (2015): we ignore the regularization term. Hence, we obtain\n",
        "\n",
        "$$c(\\alpha, w)=-\\frac{1}{N} \\sum_{i=1}^{N} \\ln \\hat{p}\\left(x_{i}, y_{i}\\right) \\ .$$\n",
        "\n",
        "In this NLL we evaluate the model's predicted fixation probability $\\hat{p}$ at the positions $(x_i,y_i)$ of each fixation $i \\in \\{1, ..., N\\}$ measured in the experiments. Note that the elements in the binary fixation masks $f(x_j, y_k)$ (our labels) count how many fixations ocurred at position $(x_j, y_k)$.\n",
        "\n",
        "Let's rewrite the NLL in a way you can directly implement into code: We compute the inner product of the model predictions at all spatial coordinates $\\hat{p}(x_j, y_k)$ and ground truth binary fixation masks $f(x_j, y_k)$ and divide by the fixation count $N$. Additionally, we compute the mean over images $b$ in our batch. This way, we obtain\n",
        "\n",
        "$$\\tilde{c}(\\alpha, w) = \\frac{1}{b} \\sum_b^B \\underbrace{ (-1) \\frac{1}{N} \\sum_{j,k} \\ln (\\hat{p}(x_{j}, y_{k} |\\, \\mathrm{image} \\ b)) \\cdot f(x_{j},y_{k} |\\, \\mathrm{image} \\ b) }_{c(\\alpha, w)} \\ .$$\n",
        "\n",
        "**Questions:**\n",
        "- Why can we re-write the expression $c(\\alpha, w)$ like this? \n",
        "- What values can the elements of $f(x_{j},y_{k} |\\, \\mathrm{image} \\ b)$ obtain?\n",
        "- On the lecture slides the loss contained a *sum* over images. Here, for practical reasons we compute the *mean* over images instead. Why is that advantageous?\n",
        "\n",
        "Implement $\\tilde{c}(\\alpha, w)$. You may want to\n",
        "- Convert the sparse binary `fixation_mask` to a dense one using `t.to_dense()` to be able to compute the inner product of $f$ with the predictions $\\hat{p}$.\n",
        "- Compute the mean across batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RBIeShPiO3z"
      },
      "source": [
        "def neg_log_likelihood(log_density, fixation_mask):\n",
        "    #TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL8H7BQmD2qT"
      },
      "source": [
        "For evaluation, we want to use the *normalized scanpath saliency* (NSS; [Peters, Iyer, Itti, and Koch (2005), Section 2.10](https://doi.org/10.1016/j.visres.2005.03.019)). To compute NSS, normalize the model's saliency map (prediction) $\\mathrm{SM}(x,y)$ to have zero mean and unit standard deviation,\n",
        "\n",
        "$$Z_{\\mathrm{SM}}(x,y) = \\frac{\\mathrm{SM}(x,y) - \\mu}{\\sigma}\\ ,$$\n",
        "\n",
        "where $\\mu$ and $\\sigma$ are the mean and the standard deviation of the saliency map, respectively. Then, average the according responses at all fixations $(x_i,y_i)$,\n",
        "\n",
        "$$\\mathrm{NSS} = \\frac{1}{N} \\sum_{i=1}^N Z_{\\mathrm{SM}}(x_i,y_i)\\ .$$ \n",
        "\n",
        "Implement this as a function.\n",
        "\n",
        "*Hints:*\n",
        "- Here, the saliency map $\\mathrm{SM}(x,y)$ is *not* in log-space, i.e. the saliency map is given as exponential of the `log_density` that the model would predict, $\\mathrm{e}^{\\hat{p}(x, y)}$.\n",
        "- Remember the hints from above: \n",
        "    - How can you rewrite/implement the sum over fixation points in terms of a inner product of the normlized saliency map and the binary fixation mask?\n",
        "    - Compute the mean across batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS6TH8miiO3z"
      },
      "source": [
        "def nss(log_density, fixation_mask):\n",
        "    #TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxHRN-_jDwfW"
      },
      "source": [
        "**Train the model**\n",
        "\n",
        "Now iterate through the dataloader to train the model on the train dataset. You can use the Adam optimizer with default parameters. You should print the NLL and the NSS of the train dataset after each training epoch to monitor the progress. Train for at least 5 epochs. You are welcome to reuse and adapt the code you used on the previous exercise sheets for model training, but you don't have to.\n",
        "\n",
        "*Hints:*\n",
        "- Do we want to maximize or minimize the negative log-likelihood?\n",
        "- In our reference implementation, after the fifth epoch we got `NLL: 10.0   NSS: 3.9`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUn7PLMBiO3z"
      },
      "source": [
        "def run_training(model, train_dataset, centerbias):\n",
        "    #TODO\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQIhz6ZyDwgT"
      },
      "source": [
        "You can save the model to disk if you want to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrTmXfFADwgV"
      },
      "source": [
        "model_file = os.path.join(main_path, 'model_name.torch')\n",
        "\n",
        "if os.path.isfile(model_file):\n",
        "    model.load_state_dict(torch.load(model_file))\n",
        "    model.eval()\n",
        "else:\n",
        "    %time run_training(model, data_loader_train, torch.tensor(center_bias, dtype=torch.float))\n",
        "    torch.save(model.state_dict(), model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSUKiNUjiO30"
      },
      "source": [
        "# get the scores for the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3avBGJIWuVk"
      },
      "source": [
        "test_data = preprocess_data(\n",
        "    images_files[\"test\"], fixation_maps_binary_files[\"test\"], fixation_maps_blurred_files[\"test\"], 256\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trv1sxKTD2q4"
      },
      "source": [
        "Here you need to extract the same feature maps as you extracted before, but now for the test images instead of the trining images. It works the same way as before for the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p77N3bjiO30"
      },
      "source": [
        "def compute_test_features(  # TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFlDLHjUiO30"
      },
      "source": [
        "save / load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y__YcYKpDwhI"
      },
      "source": [
        "features_test_file = os.path.join(main_path, \"features_test.npy\")\n",
        "\n",
        "if os.path.isfile(features_test_file):\n",
        "    features_test = np.load(features_test_file)\n",
        "else:\n",
        "    features_test = compute_test_features()\n",
        "    np.save(features_test_file, features_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El54tmmhiO31"
      },
      "source": [
        "Get the NSS scores for each test image. Print the three highest NSS scores. In our reference implementation, we got `[6.0, 7.1, 7.3]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsH_8cqyDwhM"
      },
      "source": [
        "dataset_test = ImageDataset(test_data, features=features_test)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test,\n",
        "    shuffle=False,\n",
        "    batch_size=8,\n",
        "    collate_fn=collate_fn,\n",
        "    pin_memory=False,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLZIDugMiO31"
      },
      "source": [
        "#TODO\n",
        "scores = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNiAgyyHDwgu"
      },
      "source": [
        "**Inspect the results**\n",
        "\n",
        "Let's find out how well your model performs. Use the given plot function to visualize the saliency maps for\n",
        "1. the three elements of the test dataset with the *highest NSS* and\n",
        "2. the three elements of the test dataset with the *lowest NSS*.\n",
        "\n",
        "Print the respective NSS values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MabQFX0DwhR"
      },
      "source": [
        "**Display test images with highest scores**\n",
        "\n",
        "For the images with the highest scores the predicted saliency map should look very similar to the observed fixation map.\n",
        "\n",
        "Here is an example:\n",
        "\n",
        "![alt text](https://i.imgur.com/qgUQG2W.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5619dGTDwhh"
      },
      "source": [
        "def plot(image, fixations, blurred_map, prediction):\n",
        "    fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3)\n",
        "\n",
        "    ax1.axis(\"off\")\n",
        "    ax1.imshow(image)\n",
        "    ax1.set_title(\"original image\")\n",
        "\n",
        "    ax2.axis(\"off\")\n",
        "    ax2.imshow(blurred_map, cmap=\"viridis_r\")\n",
        "    ax2.set_title(\"blurred fixation map\")\n",
        "\n",
        "    ax3.axis(\"off\")\n",
        "    ax3.imshow(prediction, cmap=\"viridis_r\")\n",
        "    ax3.set_title(\"model prediction\")\n",
        "\n",
        "    ax4.axis(\"off\")\n",
        "    ax4.imshow(image, alpha=0.5)\n",
        "    ax4.scatter(fixations[1], fixations[0], s=10, marker=\".\", c=\"b\")\n",
        "    ax4.set_title(\"overlayed with discrete fixations\")\n",
        "\n",
        "    ax5.axis(\"off\")\n",
        "    ax5.imshow(image)\n",
        "    ax5.imshow(blurred_map, alpha=0.5, cmap=\"viridis_r\")\n",
        "    ax5.set_title(\"overlayed with original image\")\n",
        "\n",
        "    ax6.axis(\"off\")\n",
        "    ax6.imshow(image)\n",
        "    ax6.imshow(prediction, alpha=0.5, cmap=\"viridis_r\")\n",
        "    ax6.set_title(\"overlayed with original image\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oRFTWSsiO31"
      },
      "source": [
        "# TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZvytUxhZgFU"
      },
      "source": [
        "**Display test images with lowest scores**\n",
        "\n",
        "Here is an example for which the prediction is poor:\n",
        "\n",
        "![alt text](https://i.imgur.com/g4rD2O1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zool0WiGiO32"
      },
      "source": [
        "# TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}